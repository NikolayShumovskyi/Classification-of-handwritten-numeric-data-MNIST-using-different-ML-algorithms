{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We classified handwritten numeric data (MNIST) by SVM\n",
    "\n",
    "Procedure\n",
    "\n",
    "① Download MNIST data\n",
    "\n",
    "② Write binary file of MNIST to CSV\n",
    "\n",
    "③ Write out the CSV data to the image data and check whether the CSV can properly write out\n",
    "\n",
    "④ Learning and evaluation with SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution\n",
    "① Download MNIST data\n",
    "Data for train / test has already been divided for MNIST data and it can be downloaded as gz file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-images-idx3-ubyte.gz downloading...\n",
      "train-labels-idx1-ubyte.gz downloading...\n",
      "t10k-images-idx3-ubyte.gz downloading...\n",
      "t10k-labels-idx1-ubyte.gz downloading...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from urllib.request import urlopen\n",
    "\n",
    "def download(fname):\n",
    "    # MNIST file from server\n",
    "    print(\"%s downloading...\" % fname)\n",
    "    with urlopen(\"http://yann.lecun.com/exdb/mnist/\" + fname) as res:\n",
    "        d = res.read()\n",
    "    #Save the data under the mnist folder under the name\n",
    "        with open(\"mnist/\" + fname, \"wb\") as f:\n",
    "            f.write(d)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    if not os.path.exists(\"mnist\"):\n",
    "        os.mkdir(\"mnist\")\n",
    "\n",
    "    download(\"train-images-idx3-ubyte.gz\") #traindset\n",
    "    download(\"train-labels-idx1-ubyte.gz\") #trainlabelset\n",
    "    download(\"t10k-images-idx3-ubyte.gz\") #testset\n",
    "    download(\"t10k-labels-idx1-ubyte.gz\") #testlabelset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ② Write binary file of MNIST to CSV\n",
    "\n",
    "Since the downloaded MNIST data is a binary file of gzip, it makes CSV data so that it can be learned.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import struct\n",
    "\n",
    "def csv_image(fname, type_):\n",
    "    \n",
    "\n",
    "    # Read image data from Gzip file\n",
    "\n",
    "    #Read in binary mode\n",
    "    with gzip.open(os.path.join(\"mnist\", fname), \"rb\") as f:\n",
    "        #\">IIII\":Read in big endian (order as seen) with packs of 4 bytes each\n",
    "        #_ :The first 4 bytes are written\n",
    "        #cnt:The next 4 bytes are the number of images\n",
    "        #row:The next 4 bytes are the number of rows\n",
    "        #cols:The next 4 bytes are the number of columns\n",
    "        _, cnt, rows, cols = struct.unpack(\">IIII\", f.read(16))\n",
    "        # Image reading\n",
    "        images = []\n",
    "        for i in range(cnt):\n",
    "            binarys = f.read(rows * cols)\n",
    "            images.append(\",\".join([str(b) for b in binarys]))\n",
    "\n",
    "    # Output as CSV result\n",
    "    with open(os.path.join(\"csv\", type_ + \"_image.csv\"), \"w\") as f:\n",
    "        f.write(\"\\n\".join(images))\n",
    "\n",
    "\n",
    "def csv_label(fname, type_):\n",
    "    \n",
    "\n",
    "    # Read label data from Gzip file\n",
    "    with gzip.open(os.path.join(\"mnist\", fname), \"rb\") as f:\n",
    "        _, cnt = struct.unpack(\">II\", f.read(8))\n",
    "        labels = []\n",
    "        for i in range(cnt):\n",
    "            label = str(struct.unpack(\"B\", f.read(1))[0])\n",
    "            labels.append(label)\n",
    "\n",
    "    # Output as CSV result.\n",
    "    with open(os.path.join(\"csv\", type_ + \"_label.csv\"), \"w\") as f:\n",
    "        f.write(\"\\n\".join(labels))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    if not os.path.exists(\"csv\"):\n",
    "        os.mkdir(\"csv\")\n",
    "\n",
    "    # Training data.\n",
    "    csv_image(\"train-images-idx3-ubyte.gz\", \"training\")\n",
    "    csv_label(\"train-labels-idx1-ubyte.gz\", \"training\")\n",
    "\n",
    "    # Test data\n",
    "    csv_image(\"t10k-images-idx3-ubyte.gz\", \"test\")\n",
    "    csv_label(\"t10k-labels-idx1-ubyte.gz\", \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ③Export CSV data to image data and check whether CSV can properly write out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "CNT = 100 #Output image data by 100 characters\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    if not os.path.exists(\"image\"):\n",
    "        os.mkdir(\"image\")\n",
    "\n",
    "    with open(os.path.join(\"csv\", \"training_image.csv\")) as f:\n",
    "        images = f.read().split(\"\\n\")\n",
    "\n",
    "    for i, image in enumerate(images[:CNT]):\n",
    "        with open(os.path.join(\"image\", \"%d.pgm\" % i), \"w\") as fw:\n",
    "            s = \"P2 28 28 255\\n\" #Write P2 (PGM format symbol), 28 * 28 size, final image number as header\n",
    "            s += \" \".join(image.split(\",\"))\n",
    "            fw.write(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Result we obtained could be found in the Project's folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ④ Learning and evaluation with SVM\n",
    "So we are prepared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18627\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18627\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start prediction\n",
      "result\n",
      "Correct answer rate =  0.902\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92        42\n",
      "           1       0.94      1.00      0.97        67\n",
      "           2       0.94      0.87      0.91        55\n",
      "           3       0.90      0.82      0.86        45\n",
      "           4       0.88      0.96      0.92        55\n",
      "           5       0.82      0.92      0.87        50\n",
      "           6       0.93      0.86      0.89        43\n",
      "           7       0.86      0.86      0.86        49\n",
      "           8       0.90      0.88      0.89        40\n",
      "           9       0.94      0.87      0.90        54\n",
      "\n",
      "    accuracy                           0.90       500\n",
      "   macro avg       0.90      0.90      0.90       500\n",
      "weighted avg       0.90      0.90      0.90       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# Train size\n",
    "SIZE_TRAINING = 5000\n",
    "\n",
    "# Test size\n",
    "SIZE_TEST = 500\n",
    "\n",
    "def load_data(type_, size):\n",
    "    \n",
    "    with open(os.path.join(\"csv\", \"%s_image.csv\" % type_)) as f:\n",
    "        images = f.read().split(\"\\n\")[:size]\n",
    "    with open(os.path.join(\"csv\", \"%s_label.csv\" % type_)) as f:\n",
    "        labels = f.read().split(\"\\n\")[:size]\n",
    "\n",
    "             #Divide the number (black and white: white 0 to black 255) \n",
    "            #corresponding to each pixel by 256 and convert it to the value 0-1\n",
    "    images = [[int(i)/256 for i in image.split(\",\")] for image in images]\n",
    "    labels = [int(l) for l in labels]\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    #Acquire training data.\n",
    "    images, labels = load_data(\"training\", SIZE_TRAINING)\n",
    "\n",
    "    #Learning\n",
    "    print(\"Learning start\")\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(images, labels)\n",
    "\n",
    "    # Acquire test data\n",
    "    images, labels = load_data(\"test\", SIZE_TEST)\n",
    "\n",
    "    # prediction\n",
    "    print(\"Start prediction\")\n",
    "    predict = clf.predict(images)\n",
    "\n",
    "    # Result representation\n",
    "    print(\"result\")\n",
    "    ac_score = metrics.accuracy_score(labels, predict)\n",
    "    cl_report = metrics.classification_report(labels, predict)\n",
    "    print(\"Correct answer rate = \", ac_score)\n",
    "    print(cl_report)\n",
    "\n",
    "    # Save results\n",
    "    if not os.path.exists(\"result\"):\n",
    "        os.mkdir(\"result\")\n",
    "    joblib.dump(clf, os.path.join(\"result\", \"svm.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Discussion\n",
    "So, our prediction rate is 0.92\n",
    "\n",
    "But is there a way to improve result?\n",
    "\n",
    "Of course there is.\n",
    "\n",
    "We've just used 5000 test points for 500 test ones.\n",
    "\n",
    "Let's increase the data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18627\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start prediction\n",
      "result\n",
      "Correct answer rate =  0.9232\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96       460\n",
      "           1       0.95      0.98      0.97       571\n",
      "           2       0.93      0.92      0.92       530\n",
      "           3       0.89      0.92      0.91       500\n",
      "           4       0.91      0.93      0.92       500\n",
      "           5       0.90      0.90      0.90       456\n",
      "           6       0.94      0.94      0.94       462\n",
      "           7       0.93      0.88      0.90       512\n",
      "           8       0.93      0.88      0.90       489\n",
      "           9       0.91      0.89      0.90       520\n",
      "\n",
      "    accuracy                           0.92      5000\n",
      "   macro avg       0.92      0.92      0.92      5000\n",
      "weighted avg       0.92      0.92      0.92      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# Train size\n",
    "SIZE_TRAINING = 50000\n",
    "\n",
    "# Test size\n",
    "SIZE_TEST = 5000\n",
    "\n",
    "def load_data(type_, size):\n",
    "    \n",
    "    with open(os.path.join(\"csv\", \"%s_image.csv\" % type_)) as f:\n",
    "        images = f.read().split(\"\\n\")[:size]\n",
    "    with open(os.path.join(\"csv\", \"%s_label.csv\" % type_)) as f:\n",
    "        labels = f.read().split(\"\\n\")[:size]\n",
    "\n",
    "             #Divide the number (black and white: white 0 to black 255) \n",
    "            #corresponding to each pixel by 256 and convert it to the value 0-1\n",
    "    images = [[int(i)/256 for i in image.split(\",\")] for image in images]\n",
    "    labels = [int(l) for l in labels]\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    #Acquire training data.\n",
    "    images, labels = load_data(\"training\", SIZE_TRAINING)\n",
    "\n",
    "    #Learning\n",
    "    print(\"Learning start\")\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(images, labels)\n",
    "\n",
    "    # Acquire test data\n",
    "    images, labels = load_data(\"test\", SIZE_TEST)\n",
    "\n",
    "    # prediction\n",
    "    print(\"Start prediction\")\n",
    "    predict = clf.predict(images)\n",
    "\n",
    "    # Result representation\n",
    "    print(\"result\")\n",
    "    ac_score = metrics.accuracy_score(labels, predict)\n",
    "    cl_report = metrics.classification_report(labels, predict)\n",
    "    print(\"Correct answer rate = \", ac_score)\n",
    "    print(cl_report)\n",
    "\n",
    "    # Save results\n",
    "    if not os.path.exists(\"result\"):\n",
    "        os.mkdir(\"result\")\n",
    "    joblib.dump(clf, os.path.join(\"result\", \"svm.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
